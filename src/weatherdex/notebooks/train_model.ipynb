{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d514ecd4",
   "metadata": {},
   "source": [
    "# Weather ML Model Training\n",
    "\n",
    "## Objective\n",
    "Train a Random Forest regression model to predict temperature based on engineered features.\n",
    "\n",
    "This notebook:\n",
    "1. Loads the engineered features from `weather_features` table\n",
    "2. Builds an ML pipeline with feature scaling\n",
    "3. Trains a Random Forest regressor\n",
    "4. Evaluates model performance (RMSE, MAE, R²)\n",
    "5. Displays feature importance\n",
    "6. Saves predictions to `weather_predictions` table\n",
    "\n",
    "**Input Table:** `weather_features`\n",
    "**Output Model:** `/tmp/weather_temperature_model`\n",
    "**Output Predictions:** `weather_predictions` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import logging\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import abs as spark_abs\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import round as spark_round\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959b3f3",
   "metadata": {},
   "source": [
    "## Section 1: Load and Explore Engineered Features\n",
    "\n",
    "Load the engineered features from the `weather_features` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered features\n",
    "try:\n",
    "    df = spark.table(\"weather_features\")\n",
    "    logger.info(\"✓ Loaded weather_features table\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load table: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"Loaded Data:\")\n",
    "print(f\"  Records: {df.count():,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {df.columns}\")\n",
    "\n",
    "print(\"\\nTarget Variable (temperature) Statistics:\")\n",
    "df.select(\"temperature\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ab25d",
   "metadata": {},
   "source": [
    "## Section 2: Define Feature Columns\n",
    "\n",
    "Define which columns to use as features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    # Time features\n",
    "    \"hour\",\n",
    "    \"day_of_week\",\n",
    "    \"day_of_year\",\n",
    "    \"month\",\n",
    "    \"timestamp_unix\",\n",
    "    # Base weather features\n",
    "    \"humidity\",\n",
    "    \"pressure\",\n",
    "    \"wind_speed\",\n",
    "    \"visibility\",\n",
    "    \"cloudiness\",\n",
    "    # Lag features\n",
    "    \"temperature_lag_1\",\n",
    "    \"temperature_lag_3\",\n",
    "    \"temperature_lag_6\",\n",
    "    \"temperature_lag_12\",\n",
    "    \"humidity_lag_1\",\n",
    "    \"humidity_lag_3\",\n",
    "    \"humidity_lag_6\",\n",
    "    \"humidity_lag_12\",\n",
    "    \"pressure_lag_1\",\n",
    "    \"pressure_lag_3\",\n",
    "    \"pressure_lag_6\",\n",
    "    \"pressure_lag_12\",\n",
    "    # Rolling features\n",
    "    \"temperature_rolling_mean_3\",\n",
    "    \"temperature_rolling_std_3\",\n",
    "    \"temperature_rolling_mean_6\",\n",
    "    \"temperature_rolling_std_6\",\n",
    "    \"temperature_rolling_mean_12\",\n",
    "    \"temperature_rolling_std_12\",\n",
    "    \"humidity_rolling_mean_3\",\n",
    "    \"humidity_rolling_mean_6\",\n",
    "    \"humidity_rolling_mean_12\",\n",
    "    \"pressure_rolling_mean_3\",\n",
    "    \"pressure_rolling_mean_6\",\n",
    "    \"pressure_rolling_mean_12\",\n",
    "    # Interaction features\n",
    "    \"temp_humidity_interaction\",\n",
    "    \"cloud_visibility_ratio\",\n",
    "    \"pressure_humidity_interaction\",\n",
    "]\n",
    "\n",
    "# Filter to only columns that exist\n",
    "available_columns = set(df.columns)\n",
    "feature_columns = [f for f in feature_columns if f in available_columns]\n",
    "\n",
    "print(\"Feature Columns to Use:\")\n",
    "print(f\"  Total: {len(feature_columns)}\")\n",
    "for i, col_name in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i:2d}. {col_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ae56d",
   "metadata": {},
   "source": [
    "## Section 3: Split Data into Training and Testing Sets\n",
    "\n",
    "Split data with 80/20 ratio for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"  Training set: {train_df.count():,} records ({100 * train_df.count() / df.count():.1f}%)\")\n",
    "print(f\"  Testing set:  {test_df.count():,} records ({100 * test_df.count() / df.count():.1f}%)\")\n",
    "print(f\"  Total:        {df.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ee5b7",
   "metadata": {},
   "source": [
    "## Section 4: Build ML Pipeline\n",
    "\n",
    "Create a pipeline with feature assembly, scaling, and Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ML Pipeline\n",
    "print(\"Building ML Pipeline...\")\n",
    "\n",
    "# Step 1: Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "\n",
    "# Step 2: Scale features (standardization)\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True\n",
    ")\n",
    "\n",
    "# Step 3: Random Forest Regressor\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"temperature\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    minInstancesPerNode=5,\n",
    "    subsamplingRate=0.8,\n",
    "    featureSubsetStrategy=\"sqrt\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Combine into pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "print(\"✓ Pipeline created with 3 stages:\")\n",
    "print(\"  1. Feature Assembly\")\n",
    "print(\"  2. Feature Scaling\")\n",
    "print(\"  3. Random Forest Regressor (50 trees, max depth=10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d3573",
   "metadata": {},
   "source": [
    "## Section 5: Train the Machine Learning Model\n",
    "\n",
    "Train the Random Forest model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bde9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training Random Forest model...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "print(\"✓ Model training completed successfully\")\n",
    "print(f\"  Trained on {train_df.count():,} records\")\n",
    "print(f\"  Using {len(feature_columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3dece",
   "metadata": {},
   "source": [
    "## Section 6: Evaluate Model Performance\n",
    "\n",
    "Calculate performance metrics on the test set (RMSE, MAE, R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Add absolute error column\n",
    "predictions = predictions.withColumn(\n",
    "    \"abs_error\", spark_abs(col(\"prediction\") - col(\"temperature\")).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"temperature\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"temperature\", predictionCol=\"prediction\", metricName=\"mae\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"temperature\", predictionCol=\"prediction\", metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nRegression Metrics (on {predictions.count():,} test samples):\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): {rmse:.4f}°C\")\n",
    "print(f\"  MAE  (Mean Absolute Error):    {mae:.4f}°C\")\n",
    "print(f\"  R²   (Coefficient of Determination): {r2:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - RMSE of {rmse:.4f}°C: Average prediction error magnitude\")\n",
    "print(f\"  - MAE of {mae:.4f}°C: Average absolute prediction error\")\n",
    "print(f\"  - R² of {r2:.4f}: Model explains {100 * r2:.1f}% of temperature variance\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90d4c7",
   "metadata": {},
   "source": [
    "## Section 7: Display Feature Importance\n",
    "\n",
    "Show the most important features used by the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d54363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "rf_model = model.stages[-1]  # Get Random Forest stage from pipeline\n",
    "importances = rf_model.featureImportances.toArray()\n",
    "\n",
    "# Map feature names to importances\n",
    "feature_importance_pairs = list(zip(feature_columns, importances, strict=False))\n",
    "feature_importance_sorted = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 20 FEATURE IMPORTANCE SCORES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Rank':<6} {'Feature Name':<40} {'Importance':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for rank, (feature_name, importance) in enumerate(feature_importance_sorted[:20], 1):\n",
    "    print(f\"{rank:<6} {feature_name:<40} {importance:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfeab5",
   "metadata": {},
   "source": [
    "## Section 8: Make Weather Predictions\n",
    "\n",
    "View sample predictions comparing actual vs predicted temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5876e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions (Best and Worst):\")\n",
    "print(\"\\nBEST PREDICTIONS (Lowest Error):\")\n",
    "predictions.orderBy(\"abs_error\").select(\n",
    "    \"city\", \"timestamp\", \"temperature\", \"prediction\", \"abs_error\"\n",
    ").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nWORST PREDICTIONS (Highest Error):\")\n",
    "predictions.orderBy(col(\"abs_error\").desc()).select(\n",
    "    \"city\", \"timestamp\", \"temperature\", \"prediction\", \"abs_error\"\n",
    ").show(5, truncate=False)\n",
    "\n",
    "# Prediction accuracy statistics\n",
    "accuracy_within_1c = predictions.filter(col(\"abs_error\") <= 1.0).count() / predictions.count() * 100\n",
    "accuracy_within_2c = predictions.filter(col(\"abs_error\") <= 2.0).count() / predictions.count() * 100\n",
    "accuracy_within_3c = predictions.filter(col(\"abs_error\") <= 3.0).count() / predictions.count() * 100\n",
    "\n",
    "print(\"\\nPrediction Accuracy:\")\n",
    "print(f\"  Within 1°C: {accuracy_within_1c:.1f}% of predictions\")\n",
    "print(f\"  Within 2°C: {accuracy_within_2c:.1f}% of predictions\")\n",
    "print(f\"  Within 3°C: {accuracy_within_3c:.1f}% of predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc799c9",
   "metadata": {},
   "source": [
    "## Section 9: Visualize Predictions vs Actual Values\n",
    "\n",
    "Compare predicted values with actual values to assess accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual analysis by city\n",
    "print(\"\\nPrediction Performance by City:\")\n",
    "print(\"-\" * 70)\n",
    "city_performance = (\n",
    "    predictions.groupBy(\"city\")\n",
    "    .agg(\n",
    "        spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "        spark_round(avg(\"temperature\"), 2).alias(\"avg_temp\"),\n",
    "        spark_round(avg(\"prediction\"), 2).alias(\"avg_prediction\"),\n",
    "    )\n",
    "    .orderBy(\"avg_error\")\n",
    ")\n",
    "\n",
    "city_performance.show(truncate=False)\n",
    "\n",
    "# Residual distribution\n",
    "print(\"\\nResidual Analysis:\")\n",
    "residuals_stats = predictions.select(\n",
    "    spark_round(avg(\"abs_error\"), 4).alias(\"mean_error\"),\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"  Mean Absolute Error: {residuals_stats['mean_error']:.4f}°C\")\n",
    "\n",
    "# Save predictions for later analysis\n",
    "print(\"\\nSaving predictions to weather_predictions table...\")\n",
    "predictions.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_predictions\")\n",
    "print(\"✓ Predictions saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366104bf",
   "metadata": {},
   "source": [
    "## Section 10: Save Trained Model\n",
    "\n",
    "Save the trained model for future predictions and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = \"/tmp/weather_temperature_model\"\n",
    "\n",
    "print(f\"\\nSaving trained model to {model_path}...\")\n",
    "try:\n",
    "    model.write().overwrite().save(model_path)\n",
    "    print(f\"✓ Model saved successfully to {model_path}\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Could not save to {model_path}, saving with alternative path: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nModel Details:\")\n",
    "print(\"  Algorithm: Random Forest Regressor\")\n",
    "print(\"  Number of Trees: 50\")\n",
    "print(\"  Max Depth: 10\")\n",
    "print(f\"  Features Used: {len(feature_columns)}\")\n",
    "print(f\"  Training Samples: {train_df.count():,}\")\n",
    "print(f\"  Test Samples: {test_df.count():,}\")\n",
    "print(\"\\nPerformance:\")\n",
    "print(f\"  RMSE: {rmse:.4f}°C\")\n",
    "print(f\"  MAE:  {mae:.4f}°C\")\n",
    "print(f\"  R²:   {r2:.4f}\")\n",
    "print(\"\\nOutputs Generated:\")\n",
    "print(\"  ✓ weather_predictions table (predictions + actual values)\")\n",
    "print(\"  ✓ /tmp/weather_temperature_model (trained model)\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Run analyze_predictions.py for detailed analysis\")\n",
    "print(\"  2. Deploy model for production use\")\n",
    "print(\"  3. Monitor prediction accuracy over time\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
