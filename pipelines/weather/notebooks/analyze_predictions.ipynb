{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36dbfa49",
   "metadata": {},
   "source": [
    "# Weather ML Prediction Analysis\n",
    "\n",
    "## Objective\n",
    "Analyze model predictions to understand:\n",
    "- Performance by city\n",
    "- Performance by hour of day\n",
    "- Performance by day of week\n",
    "- Performance by weather condition\n",
    "- Prediction error distributions\n",
    "- Residual patterns\n",
    "\n",
    "This notebook:\n",
    "1. Loads predictions from `weather_predictions` table\n",
    "2. Performs city-wise analysis\n",
    "3. Performs hourly analysis\n",
    "4. Performs day-of-week analysis\n",
    "5. Performs condition-based analysis\n",
    "6. Saves analysis results to `weather_analysis` table\n",
    "\n",
    "**Input Table:** `weather_predictions`\n",
    "**Output Table:** `weather_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, abs as spark_abs, round as spark_round, \n",
    "    avg, stddev, max as spark_max, min as spark_min,\n",
    "    count, when, desc\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f8668",
   "metadata": {},
   "source": [
    "## Section 1: Load Predictions\n",
    "\n",
    "Load the model predictions from `weather_predictions` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10102146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "try:\n",
    "    predictions = spark.table(\"weather_predictions\")\n",
    "    logger.info(\"✓ Loaded weather_predictions table\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load table: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"Loaded Predictions:\")\n",
    "print(f\"  Total records: {predictions.count():,}\")\n",
    "print(f\"  Columns: {len(predictions.columns)}\")\n",
    "\n",
    "# Ensure abs_error column exists\n",
    "if \"abs_error\" not in predictions.columns:\n",
    "    predictions = predictions.withColumn(\n",
    "        \"abs_error\",\n",
    "        spark_abs(col(\"prediction\") - col(\"temperature\")).cast(DoubleType())\n",
    "    )\n",
    "    print(\"  Created abs_error column\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample Predictions:\")\n",
    "predictions.select(\"city\", \"timestamp\", \"temperature\", \"prediction\", \"abs_error\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a055ce",
   "metadata": {},
   "source": [
    "## Section 2: City-Wise Performance Analysis\n",
    "\n",
    "Analyze prediction accuracy by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City-wise performance analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CITY-WISE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "city_analysis = predictions.groupBy(\"city\").agg(\n",
    "    count(\"*\").alias(\"predictions\"),\n",
    "    spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "    spark_round(stddev(\"abs_error\"), 4).alias(\"std_error\"),\n",
    "    spark_round(spark_min(\"abs_error\"), 4).alias(\"min_error\"),\n",
    "    spark_round(spark_max(\"abs_error\"), 4).alias(\"max_error\"),\n",
    "    spark_round(avg(\"temperature\"), 2).alias(\"avg_actual_temp\"),\n",
    "    spark_round(avg(\"prediction\"), 2).alias(\"avg_predicted_temp\"),\n",
    "    (count(when(col(\"abs_error\") <= 1.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_1c_pct\"),\n",
    "    (count(when(col(\"abs_error\") <= 2.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_2c_pct\")\n",
    ").orderBy(\"avg_error\")\n",
    "\n",
    "city_analysis.show(truncate=False)\n",
    "\n",
    "# Save city analysis\n",
    "city_analysis.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_analysis_by_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc623a8",
   "metadata": {},
   "source": [
    "## Section 3: Hourly Performance Analysis\n",
    "\n",
    "Analyze prediction accuracy by hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3745014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly performance analysis (if hour column exists)\n",
    "if \"hour\" in predictions.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"HOURLY PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    hourly_analysis = predictions.groupBy(\"hour\").agg(\n",
    "        count(\"*\").alias(\"predictions\"),\n",
    "        spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "        spark_round(stddev(\"abs_error\"), 4).alias(\"std_error\"),\n",
    "        spark_round(avg(\"temperature\"), 2).alias(\"avg_actual_temp\"),\n",
    "        spark_round(avg(\"prediction\"), 2).alias(\"avg_predicted_temp\"),\n",
    "        (count(when(col(\"abs_error\") <= 2.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_2c_pct\")\n",
    "    ).orderBy(\"hour\")\n",
    "    \n",
    "    hourly_analysis.show(truncate=False)\n",
    "    \n",
    "    # Save hourly analysis\n",
    "    hourly_analysis.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_analysis_by_hour\")\n",
    "else:\n",
    "    print(\"Hour column not available for hourly analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc922fc4",
   "metadata": {},
   "source": [
    "## Section 4: Day-of-Week Performance Analysis\n",
    "\n",
    "Analyze prediction accuracy by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf38440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day-of-week performance analysis\n",
    "if \"day_of_week\" in predictions.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DAY-OF-WEEK PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    day_names = {1: \"Sunday\", 2: \"Monday\", 3: \"Tuesday\", 4: \"Wednesday\",\n",
    "                 5: \"Thursday\", 6: \"Friday\", 7: \"Saturday\"}\n",
    "    \n",
    "    daily_analysis = predictions.groupBy(\"day_of_week\").agg(\n",
    "        count(\"*\").alias(\"predictions\"),\n",
    "        spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "        spark_round(stddev(\"abs_error\"), 4).alias(\"std_error\"),\n",
    "        spark_round(avg(\"temperature\"), 2).alias(\"avg_actual_temp\"),\n",
    "        (count(when(col(\"abs_error\") <= 2.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_2c_pct\")\n",
    "    ).withColumn(\n",
    "        \"day_name\",\n",
    "        when(col(\"day_of_week\") == 1, \"Sunday\")\n",
    "        .when(col(\"day_of_week\") == 2, \"Monday\")\n",
    "        .when(col(\"day_of_week\") == 3, \"Tuesday\")\n",
    "        .when(col(\"day_of_week\") == 4, \"Wednesday\")\n",
    "        .when(col(\"day_of_week\") == 5, \"Thursday\")\n",
    "        .when(col(\"day_of_week\") == 6, \"Friday\")\n",
    "        .when(col(\"day_of_week\") == 7, \"Saturday\")\n",
    "    ).orderBy(\"day_of_week\")\n",
    "    \n",
    "    daily_analysis.show(truncate=False)\n",
    "    \n",
    "    # Save daily analysis\n",
    "    daily_analysis.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_analysis_by_day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae40847",
   "metadata": {},
   "source": [
    "## Section 5: Weather Condition Performance Analysis\n",
    "\n",
    "Analyze prediction accuracy by weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather condition performance analysis\n",
    "if \"condition\" in predictions.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"WEATHER CONDITION PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    condition_analysis = predictions.groupBy(\"condition\").agg(\n",
    "        count(\"*\").alias(\"predictions\"),\n",
    "        spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "        spark_round(stddev(\"abs_error\"), 4).alias(\"std_error\"),\n",
    "        spark_round(spark_min(\"abs_error\"), 4).alias(\"min_error\"),\n",
    "        spark_round(spark_max(\"abs_error\"), 4).alias(\"max_error\"),\n",
    "        spark_round(avg(\"temperature\"), 2).alias(\"avg_actual_temp\"),\n",
    "        (count(when(col(\"abs_error\") <= 2.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_2c_pct\")\n",
    "    ).orderBy(\"avg_error\")\n",
    "    \n",
    "    condition_analysis.show(truncate=False)\n",
    "    \n",
    "    # Save condition analysis\n",
    "    condition_analysis.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_analysis_by_condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31cdfb0",
   "metadata": {},
   "source": [
    "## Section 6: Residual and Error Distribution Analysis\n",
    "\n",
    "Analyze error distribution and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ed264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESIDUAL AND ERROR DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "residual_stats = predictions.select(\n",
    "    spark_round(avg(\"abs_error\"), 4).alias(\"mean_abs_error\"),\n",
    "    spark_round(stddev(\"abs_error\"), 4).alias(\"std_abs_error\"),\n",
    "    spark_round(spark_min(\"abs_error\"), 4).alias(\"min_abs_error\"),\n",
    "    spark_round(spark_max(\"abs_error\"), 4).alias(\"max_abs_error\")\n",
    ").collect()[0]\n",
    "\n",
    "print(\"\\nError Statistics:\")\n",
    "print(f\"  Mean Absolute Error:     {residual_stats['mean_abs_error']:.4f}°C\")\n",
    "print(f\"  Std Dev Absolute Error:  {residual_stats['std_abs_error']:.4f}°C\")\n",
    "print(f\"  Min Absolute Error:      {residual_stats['min_abs_error']:.4f}°C\")\n",
    "print(f\"  Max Absolute Error:      {residual_stats['max_abs_error']:.4f}°C\")\n",
    "\n",
    "# Accuracy by error range\n",
    "print(\"\\nPrediction Accuracy by Error Range:\")\n",
    "for error_threshold in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]:\n",
    "    accuracy = predictions.filter(col(\"abs_error\") <= error_threshold).count() / predictions.count() * 100\n",
    "    print(f\"  Within {error_threshold}°C: {accuracy:.1f}% of predictions\")\n",
    "\n",
    "# Save residual statistics\n",
    "residual_df = spark.createDataFrame(\n",
    "    [(residual_stats['mean_abs_error'], \n",
    "      residual_stats['std_abs_error'],\n",
    "      residual_stats['min_abs_error'],\n",
    "      residual_stats['max_abs_error'])],\n",
    "    ['mean_abs_error', 'std_abs_error', 'min_abs_error', 'max_abs_error']\n",
    ")\n",
    "residual_df.write.mode(\"overwrite\").saveAsTable(\"weather_residual_statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f4279",
   "metadata": {},
   "source": [
    "## Section 7: Temperature Range Analysis\n",
    "\n",
    "Analyze prediction accuracy across different temperature ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature range analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMPERATURE RANGE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "temp_range_analysis = predictions.withColumn(\n",
    "    \"temp_range\",\n",
    "    when(col(\"temperature\") < 0, \"Below 0°C\")\n",
    "    .when(col(\"temperature\") < 10, \"0-10°C\")\n",
    "    .when(col(\"temperature\") < 20, \"10-20°C\")\n",
    "    .when(col(\"temperature\") < 30, \"20-30°C\")\n",
    "    .otherwise(\"Above 30°C\")\n",
    ").groupBy(\"temp_range\").agg(\n",
    "    count(\"*\").alias(\"predictions\"),\n",
    "    spark_round(avg(\"abs_error\"), 4).alias(\"avg_error\"),\n",
    "    spark_round(avg(\"temperature\"), 2).alias(\"avg_temp\"),\n",
    "    (count(when(col(\"abs_error\") <= 2.0, 1)) / count(\"*\") * 100).alias(\"accuracy_within_2c_pct\")\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance by Temperature Range:\")\n",
    "temp_range_analysis.show(truncate=False)\n",
    "\n",
    "# Save temperature range analysis\n",
    "temp_range_analysis.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"weather_analysis_by_temp_range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74adf13",
   "metadata": {},
   "source": [
    "## Section 8: Summary and Final Report\n",
    "\n",
    "Generate comprehensive summary of analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce578b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary report\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WEATHER ML PREDICTION ANALYSIS - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total Predictions: {predictions.count():,}\")\n",
    "print(f\"  Mean Temperature: {predictions.select(avg('temperature')).collect()[0][0]:.2f}°C\")\n",
    "print(f\"  Mean Error: {residual_stats['mean_abs_error']:.4f}°C\")\n",
    "\n",
    "print(f\"\\nAnalysis Tables Created:\")\n",
    "print(f\"  ✓ weather_analysis_by_city\")\n",
    "print(f\"  ✓ weather_analysis_by_hour (if hour data available)\")\n",
    "print(f\"  ✓ weather_analysis_by_day (if day data available)\")\n",
    "print(f\"  ✓ weather_analysis_by_condition (if condition data available)\")\n",
    "print(f\"  ✓ weather_analysis_by_temp_range\")\n",
    "print(f\"  ✓ weather_residual_statistics\")\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  - Best accuracy within: 2.0°C\")\n",
    "print(f\"  - Average prediction error: {residual_stats['mean_abs_error']:.4f}°C\")\n",
    "print(f\"  - Standard deviation: {residual_stats['std_abs_error']:.4f}°C\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREDICTION ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Review city-wise performance table\")\n",
    "print(\"  2. Monitor weather conditions with high errors\")\n",
    "print(\"  3. Consider retraining with more data if accuracy is low\")\n",
    "print(\"  4. Use predictions for downstream applications\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
