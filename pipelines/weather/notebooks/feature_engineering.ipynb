{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f67b78",
   "metadata": {},
   "source": [
    "# Weather ML Feature Engineering\n",
    "\n",
    "## Objective\n",
    "Create comprehensive ML features from raw weather data for temperature prediction.\n",
    "\n",
    "This notebook:\n",
    "1. Loads weather data from the `weather_current` table\n",
    "2. Creates time-based features (hour, day of week, month, etc.)\n",
    "3. Creates lag features (previous observations)\n",
    "4. Creates rolling window statistics\n",
    "5. Creates interaction features\n",
    "6. Saves engineered features to `weather_features` table\n",
    "\n",
    "**Output Table:** `weather_features`\n",
    "**Target Variable:** `temperature`\n",
    "**Total Features:** 25+ engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    col,\n",
    "    count,\n",
    "    dayofweek,\n",
    "    dayofyear,\n",
    "    hour,\n",
    "    lag,\n",
    "    month,\n",
    "    stddev,\n",
    "    unix_timestamp,\n",
    "    when,\n",
    ")\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522890f",
   "metadata": {},
   "source": [
    "## Section 1: Load and Explore Weather Data\n",
    "\n",
    "Load raw weather data from the `weather_current` table and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "try:\n",
    "    df = spark.table(\"weather_current\")\n",
    "    logger.info(\"✓ Loaded weather_current table\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load table: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display schema\n",
    "print(\"Data Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nTotal Records: {df.count()}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample Data:\")\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63881131",
   "metadata": {},
   "source": [
    "## Section 2: Create Time-Based Features\n",
    "\n",
    "Extract temporal features from timestamp (hour, day of week, month, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df_features = df.withColumn(\n",
    "    \"timestamp_unix\",\n",
    "    unix_timestamp(col(\"timestamp\"), \"yyyy-MM-dd'T'HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"hour\",\n",
    "    hour(col(\"timestamp\")).cast(IntegerType())\n",
    ").withColumn(\n",
    "    \"day_of_week\",\n",
    "    dayofweek(col(\"timestamp\")).cast(IntegerType())\n",
    ").withColumn(\n",
    "    \"day_of_year\",\n",
    "    dayofyear(col(\"timestamp\")).cast(IntegerType())\n",
    ").withColumn(\n",
    "    \"month\",\n",
    "    month(col(\"timestamp\")).cast(IntegerType())\n",
    ")\n",
    "\n",
    "print(\"✓ Created time-based features:\")\n",
    "print(\"  - timestamp_unix\")\n",
    "print(\"  - hour (0-23)\")\n",
    "print(\"  - day_of_week (1-7)\")\n",
    "print(\"  - day_of_year (1-365)\")\n",
    "print(\"  - month (1-12)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53363579",
   "metadata": {},
   "source": [
    "## Section 3: Create Lag Features\n",
    "\n",
    "Create features based on previous observations (1, 3, 6, 12 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68595a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create window for lag features (partitioned by city, ordered by timestamp)\n",
    "window_spec = Window.partitionBy(\"city\").orderBy(\"timestamp\")\n",
    "\n",
    "# Create lag features for multiple metrics\n",
    "lag_values = [1, 3, 6, 12]\n",
    "\n",
    "for lag_val in lag_values:\n",
    "    df_features = df_features.withColumn(\n",
    "        f\"temperature_lag_{lag_val}\",\n",
    "        lag(\"temperature\", lag_val).over(window_spec).cast(DoubleType())\n",
    "    ).withColumn(\n",
    "        f\"humidity_lag_{lag_val}\",\n",
    "        lag(\"humidity\", lag_val).over(window_spec).cast(DoubleType())\n",
    "    ).withColumn(\n",
    "        f\"pressure_lag_{lag_val}\",\n",
    "        lag(\"pressure\", lag_val).over(window_spec).cast(DoubleType())\n",
    "    )\n",
    "\n",
    "print(\"✓ Created lag features:\")\n",
    "for lag_val in lag_values:\n",
    "    print(f\"  - Lag {lag_val}: temperature_lag_{lag_val}, humidity_lag_{lag_val}, pressure_lag_{lag_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5d0e6",
   "metadata": {},
   "source": [
    "## Section 4: Create Rolling Window Features\n",
    "\n",
    "Create statistics over rolling windows (3, 6, 12 hour windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window features\n",
    "window_sizes = [3, 6, 12]\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    # Create window spec for rolling calculations (by time)\n",
    "    window_spec_rolling = Window.partitionBy(\"city\").orderBy(\n",
    "        \"timestamp_unix\"\n",
    "    ).rangeBetween(\n",
    "        -(window_size * 3600 - 1), 0  # Window size in seconds\n",
    "    )\n",
    "    \n",
    "    # Create rolling mean and std for temperature\n",
    "    df_features = df_features.withColumn(\n",
    "        f\"temperature_rolling_mean_{window_size}\",\n",
    "        avg(\"temperature\").over(window_spec_rolling).cast(DoubleType())\n",
    "    ).withColumn(\n",
    "        f\"temperature_rolling_std_{window_size}\",\n",
    "        stddev(\"temperature\").over(window_spec_rolling).cast(DoubleType())\n",
    "    )\n",
    "    \n",
    "    # Create rolling mean for humidity and pressure\n",
    "    df_features = df_features.withColumn(\n",
    "        f\"humidity_rolling_mean_{window_size}\",\n",
    "        avg(\"humidity\").over(window_spec_rolling).cast(DoubleType())\n",
    "    ).withColumn(\n",
    "        f\"pressure_rolling_mean_{window_size}\",\n",
    "        avg(\"pressure\").over(window_spec_rolling).cast(DoubleType())\n",
    "    )\n",
    "\n",
    "print(\"✓ Created rolling window features:\")\n",
    "for window_size in window_sizes:\n",
    "    print(f\"  - Window {window_size}h: mean & std temperature, mean humidity & pressure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e508d",
   "metadata": {},
   "source": [
    "## Section 5: Create Interaction Features\n",
    "\n",
    "Create derived features from combinations of base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction features\n",
    "df_features = df_features.withColumn(\n",
    "    \"temp_humidity_interaction\",\n",
    "    (col(\"temperature\") * col(\"humidity\") / 100).cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"cloud_visibility_ratio\",\n",
    "    (col(\"cloudiness\") / (col(\"visibility\") + 0.1)).cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"pressure_humidity_interaction\",\n",
    "    (col(\"pressure\") * col(\"humidity\") / 1000).cast(DoubleType())\n",
    ")\n",
    "\n",
    "print(\"✓ Created interaction features:\")\n",
    "print(\"  - temp_humidity_interaction: temperature × (humidity / 100)\")\n",
    "print(\"  - cloud_visibility_ratio: cloudiness / (visibility + 0.1)\")\n",
    "print(\"  - pressure_humidity_interaction: pressure × (humidity / 1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd0479",
   "metadata": {},
   "source": [
    "## Section 6: Handle Missing Values\n",
    "\n",
    "Drop rows with null values (necessary after creating lag and rolling features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "records_before = df_features.count()\n",
    "df_features = df_features.dropna()\n",
    "records_after = df_features.count()\n",
    "\n",
    "print(\"✓ Dropped null values:\")\n",
    "print(f\"  Records before: {records_before}\")\n",
    "print(f\"  Records after:  {records_after}\")\n",
    "print(f\"  Records removed: {records_before - records_after} ({100*(records_before-records_after)/records_before:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b918c",
   "metadata": {},
   "source": [
    "## Section 7: Feature Summary\n",
    "\n",
    "Display the engineered features and save to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1959dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature summary\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nFinal Dataset:\")\n",
    "print(f\"  Total Records: {df_features.count():,}\")\n",
    "print(f\"  Total Features: {len(df_features.columns)}\")\n",
    "print(\"  Target Variable: temperature\")\n",
    "\n",
    "print(\"\\nFeature Categories:\")\n",
    "print(\"  Time Features: hour, day_of_week, day_of_year, month, timestamp_unix\")\n",
    "print(\"  Base Features: humidity, pressure, wind_speed, visibility, cloudiness\")\n",
    "print(\"  Lag Features: 12 features (temperature, humidity, pressure × 4 lags)\")\n",
    "print(\"  Rolling Features: 12 features (temperature mean/std, humidity/pressure mean × 3 windows)\")\n",
    "print(\"  Interaction Features: 3 features (interactions)\")\n",
    "\n",
    "print(\"\\nData Distribution by City:\")\n",
    "df_features.groupBy(\"city\").count().show(truncate=False)\n",
    "\n",
    "print(\"\\nSample Features:\")\n",
    "display_cols = [\"city\", \"timestamp\", \"temperature\", \"humidity\", \"pressure\", \"hour\", \"day_of_week\"]\n",
    "display_cols = [c for c in display_cols if c in df_features.columns]\n",
    "df_features.select(*display_cols).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a2a1b",
   "metadata": {},
   "source": [
    "## Section 8: Save to Delta Lake\n",
    "\n",
    "Save the engineered features to the `weather_features` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to Delta Lake\n",
    "print(\"Saving engineered features to weather_features table...\")\n",
    "\n",
    "try:\n",
    "    df_features.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(\"weather_features\")\n",
    "    \n",
    "    print(\"✓ Successfully saved to weather_features table\")\n",
    "    \n",
    "    # Verify saved data\n",
    "    verify_df = spark.table(\"weather_features\")\n",
    "    print(\"\\nVerification:\")\n",
    "    print(f\"  Rows saved: {verify_df.count():,}\")\n",
    "    print(f\"  Columns saved: {len(verify_df.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to save table: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Train temperature prediction model (train_model.py)\")\n",
    "print(\"2. Analyze predictions (analyze_predictions.py)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
