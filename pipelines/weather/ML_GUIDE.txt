================================================================================
WEATHER ML MODEL - TEMPERATURE PREDICTION GUIDE
================================================================================

PROJECT OVERVIEW
================

Machine Learning model for predicting temperature based on:
- Historical weather patterns (lagged features)
- Time-based patterns (hour, day, month, day of week)
- Rolling window statistics (3, 6, 12 hour windows)
- Weather condition interactions
- City-specific patterns

MODEL ARCHITECTURE
==================

Pipeline Flow:
1. extract_weather.py     → Fetch current weather data (API)
2. load_weather.py        → Store in Delta Lake (weather_current)
3. feature_engineering.py → Create ML features (weather_features)
4. train_model.py         → Train Random Forest (weather_temperature_model)
5. analyze_predictions.py → Evaluate & analyze results (weather_analysis)

DATA FLOW
=========

INPUT DATA (weather_current table)
├─ city: STRING
├─ country: STRING
├─ temperature: DOUBLE (target variable)
├─ feels_like: DOUBLE
├─ humidity: INTEGER (%)
├─ pressure: INTEGER (hPa)
├─ condition: STRING
├─ description: STRING
├─ wind_speed: DOUBLE (m/s)
├─ visibility: DOUBLE (km)
├─ cloudiness: INTEGER (%)
└─ timestamp: STRING (ISO format)

FEATURE ENGINEERING
===================

1. TIME-BASED FEATURES
   ├─ hour: 0-23 (hour of day)
   ├─ day_of_week: 1-7 (Monday=2, Sunday=1)
   ├─ day_of_year: 1-365
   ├─ month: 1-12
   └─ timestamp_unix: Unix timestamp

2. LAG FEATURES (Previous observations)
   ├─ temperature_lag_1: Previous 1 observation
   ├─ temperature_lag_3: Previous 3 observations
   ├─ temperature_lag_6: Previous 6 observations
   ├─ temperature_lag_12: Previous 12 observations
   ├─ humidity_lag_1, humidity_lag_3, humidity_lag_6, humidity_lag_12
   └─ pressure_lag_1, pressure_lag_3, pressure_lag_6, pressure_lag_12

3. ROLLING WINDOW FEATURES (3, 6, 12 hour windows)
   ├─ temperature_rolling_mean_3
   ├─ temperature_rolling_std_3
   ├─ temperature_rolling_mean_6
   ├─ temperature_rolling_std_6
   ├─ temperature_rolling_mean_12
   ├─ temperature_rolling_std_12
   ├─ humidity_rolling_mean_3/6/12
   └─ pressure_rolling_mean_3/6/12

4. INTERACTION FEATURES
   ├─ temp_humidity_interaction: temperature × (humidity / 100)
   ├─ cloud_visibility_ratio: cloudiness / (visibility + 0.1)
   └─ pressure_humidity_interaction: pressure × (humidity / 1000)

5. DERIVED FEATURES
   ├─ All original features (humidity, pressure, wind_speed, etc.)
   ├─ Normalized via StandardScaler
   └─ Assembled into feature vector

MODEL SPECIFICATION
===================

Algorithm: Random Forest Regression
├─ Number of trees: 50
├─ Max depth: 10
├─ Min instances per node: 5
├─ Feature subset strategy: sqrt (√n features per tree)
├─ Subsampling rate: 80%
└─ Seed: 42 (reproducibility)

Training Configuration:
├─ Train/test split: 80/20
├─ Loss function: Mean Squared Error
├─ Evaluation metrics: RMSE, MAE, R²
└─ Feature scaling: StandardScaler (mean=0, std=1)

EXPECTED PERFORMANCE
====================

Based on typical weather data:
├─ RMSE: 2-3°C (typical for daily temperature)
├─ MAE: 1.5-2.5°C
├─ R²: 0.70-0.85 (explains 70-85% of temperature variance)
└─ Best performance: Stable weather conditions

Factors affecting accuracy:
├─ Data freshness (older data = lower accuracy)
├─ Weather volatility (storms = harder to predict)
├─ Geographic diversity (coastal vs inland affects patterns)
├─ Temporal patterns (seasonal variations)
└─ Number of features (more relevant features = better)

FEATURE IMPORTANCE (Typical)
============================

Top features usually include:
1. Previous observations (lag features)
2. Rolling mean temperatures
3. Hour of day
4. Day of week
5. Humidity metrics
6. Pressure metrics
7. Wind speed
8. Cloudiness
9. Interaction features
10. Seasonal indicators (month, day_of_year)

NOTEBOOKS STRUCTURE
===================

1. feature_engineering.py (Task 1)
   Purpose: Create ML features from raw data
   Input: weather_current table
   Output: weather_features table
   Process:
     - Load weather data
     - Create time features
     - Create lag features (1, 3, 6, 12 observations)
     - Create rolling window statistics
     - Create interaction features
     - Drop null values
     - Save to weather_features table

2. train_model.py (Task 2)
   Purpose: Train temperature prediction model
   Input: weather_features table
   Output: weather_temperature_model (saved to /tmp/)
   Process:
     - Load engineered features
     - Create feature vector
     - Split data (80/20)
     - Train Random Forest model
     - Evaluate performance (RMSE, MAE, R²)
     - Display feature importance
     - Save model and predictions

3. analyze_predictions.py (Task 3)
   Purpose: Analyze prediction accuracy
   Input: weather_predictions table
   Output: weather_analysis table
   Analysis:
     - City-wise performance
     - Hourly accuracy patterns
     - Day-of-week patterns
     - Temperature range analysis
     - Best/worst predictions
     - Condition-based accuracy
     - Residual analysis

RUNNING THE ML PIPELINE
=======================

Step 1: Feature Engineering
  Command: databricks workspace import & run feature_engineering.py
  Duration: ~2-3 minutes
  Output: weather_features table with engineered features

Step 2: Model Training
  Command: databricks workspace import & run train_model.py
  Duration: ~3-5 minutes
  Output: Trained model + predictions table

Step 3: Prediction Analysis
  Command: databricks workspace import & run analyze_predictions.py
  Duration: ~1-2 minutes
  Output: Detailed analysis tables

USING THE MODEL PROGRAMMATICALLY
================================

Python Example:
```python
from pipelines.weather.ml import WeatherFeatureEngineer, WeatherModelTrainer

# Feature engineering
engineer = WeatherFeatureEngineer(spark)
features_df = engineer.prepare_training_data(data_df)

# Model training
trainer = WeatherModelTrainer(spark)
model, metrics = trainer.train_temperature_model(features_df)

# Make predictions
predictions = model.transform(test_df)
```

PySpark SQL Example:
```sql
-- Get feature engineered data
SELECT * FROM weather_features LIMIT 100;

-- View predictions
SELECT city, timestamp, temperature, prediction, abs_error
FROM weather_predictions
WHERE abs_error < 2.0
ORDER BY timestamp DESC;

-- City performance
SELECT city, 
       COUNT(*) as predictions,
       AVG(abs_error) as avg_error,
       MAX(abs_error) as max_error
FROM weather_predictions
GROUP BY city
ORDER BY avg_error;
```

MODEL DEPLOYMENT
================

To deploy the trained model:

1. Location: /tmp/weather_temperature_model
2. Format: PySpark MLlib pipeline model
3. Size: ~10-50MB (depends on tree depth)
4. Dependencies: PySpark, ML libraries

Production Deployment Considerations:
├─ Retraining schedule (daily/weekly)
├─ Model versioning (save with timestamp)
├─ Performance monitoring
├─ Feature drift detection
└─ A/B testing (new vs old model)

TROUBLESHOOTING
===============

Issue: Null values in features
Solution: dropna() automatically applied, or increase lag values

Issue: Low R² score
Solution: 
  - Add more weather stations/cities
  - Include more historical data
  - Feature engineering refinement
  - Hyperparameter tuning

Issue: Model inference is slow
Solution:
  - Reduce number of trees (20-30 instead of 50)
  - Reduce max depth (8 instead of 10)
  - Cache feature vectors

PERFORMANCE OPTIMIZATION
========================

For faster training:
├─ Sample data: train on subset first
├─ Reduce tree count: 20-30 trees
├─ Reduce tree depth: 5-8 levels
├─ Increase minInstancesPerNode: 10-20
└─ Use fewer lag windows

For production inference:
├─ Cache engineered features
├─ Use broadcast for small tables
├─ Partition by city for parallelization
└─ Stream predictions for real-time use

NEXT STEPS & ENHANCEMENTS
=========================

Short Term:
├─ [ ] Monitor model accuracy daily
├─ [ ] Add precipitation prediction
├─ [ ] Add humidity prediction
└─ [ ] Create ensemble model (RF + GBT)

Medium Term:
├─ [ ] Time series forecasting (multi-step ahead)
├─ [ ] Anomaly detection in weather patterns
├─ [ ] Extreme weather alerts
└─ [ ] Regional weather comparison

Long Term:
├─ [ ] Deep learning models (LSTM, Transformer)
├─ [ ] External features (solar radiation, pressure maps)
├─ [ ] Model auto-retraining pipeline
└─ [ ] REST API for predictions

MONITORING & MAINTENANCE
========================

Key metrics to track:
├─ RMSE and MAE trends
├─ Prediction error distribution
├─ Feature drift (distributions changing)
├─ Model performance by city
└─ Data quality metrics

Maintenance tasks:
├─ Weekly: Review prediction errors
├─ Monthly: Retrain with new data
├─ Quarterly: Feature engineering review
└─ Annually: Model architecture review

FILES & LOCATIONS
=================

Core ML Module:
├─ pipelines/weather/ml/ml_utils.py      (ML classes)
└─ pipelines/weather/ml/__init__.py       (Module export)

Notebooks:
├─ pipelines/weather/notebooks/feature_engineering.py
├─ pipelines/weather/notebooks/train_model.py
└─ pipelines/weather/notebooks/analyze_predictions.py

Models & Data:
├─ /tmp/weather_temperature_model         (Trained model)
├─ weather_features table                 (Engineered features)
├─ weather_predictions table              (Model output)
└─ weather_analysis table                 (Analysis results)

CONFIGURATION & CUSTOMIZATION
==============================

To change model parameters, edit train_model.py:

```python
# Adjust tree count
numTrees=100  # Default: 50

# Adjust tree depth
maxDepth=15   # Default: 10

# Adjust minimum samples per leaf
minInstancesPerNode=10  # Default: 5

# Adjust feature subsampling
subsamplingRate=0.7  # Default: 0.8
```

To add/remove features, edit feature_engineering.py:

```python
# Add lag features
for lag_val in [1, 2, 3, 6, 12, 24]:  # Add 2, 24
    df = df.withColumn(...)

# Add rolling windows
for window_size in [2, 3, 6, 12]:  # Add 2
    df = df.withColumn(...)
```

================================================================================
Generated: 2026-01-13
Weather ML Model - Production Ready
================================================================================
